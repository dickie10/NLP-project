{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "def print_statistics(y, y_pred):\n",
        "    accuracy = metrics.accuracy_score(y, y_pred)\n",
        "    precision = metrics.precision_score(y, y_pred, average='weighted')\n",
        "    recall = metrics.recall_score(y, y_pred, average='weighted')\n",
        "    f_score = metrics.f1_score(y, y_pred, average='weighted')\n",
        "    print(f'Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF_score: {f_score}\\n')\n",
        "    print(metrics.classification_report(y, y_pred))\n",
        "    return accuracy, precision, recall, f_score\n",
        "\n"
      ],
      "metadata": {
        "id": "MNN4UG0eauZ8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "LoeNqrQea2af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZlh8kU0aFsB",
        "outputId": "1e25f2ad-9d46-4f7b-f273-0de620ed68e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1429: FutureWarning: The repository for fever contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/fever\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 417ms/step - loss: 1.0814 - accuracy: 0.6833 - val_loss: 1.0642 - val_accuracy: 0.6000\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.0457 - accuracy: 0.6833 - val_loss: 1.0313 - val_accuracy: 0.6000\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.9931 - accuracy: 0.6833 - val_loss: 0.9903 - val_accuracy: 0.6000\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.9209 - accuracy: 0.6833 - val_loss: 0.9504 - val_accuracy: 0.6000\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.8466 - accuracy: 0.6833 - val_loss: 1.1194 - val_accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 326ms/step\n",
            "Accuracy: 0.72\n",
            "Precision: 0.5184\n",
            "Recall: 0.72\n",
            "F_score: 0.6027906976744185\n",
            "\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "NOT ENOUGH INFO       0.00      0.00      0.00         1\n",
            "        REFUTES       0.00      0.00      0.00         6\n",
            "       SUPPORTS       0.72      1.00      0.84        18\n",
            "\n",
            "       accuracy                           0.72        25\n",
            "      macro avg       0.24      0.33      0.28        25\n",
            "   weighted avg       0.52      0.72      0.60        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.72, 0.5184, 0.72, 0.6027906976744185)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset('fever', 'v1.0', split='train')\n",
        "df = pd.DataFrame(dataset)[:100]\n",
        "\n",
        "# Choose target and features\n",
        "y = df.label\n",
        "df_features = ['claim']\n",
        "X = df[df_features]\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "max_len = 100  # Adjust as needed\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train['claim'])\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train['claim'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test['claim'])\n",
        "\n",
        "X_train_padded = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "# Build an RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_len))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_padded, y_train_encoded, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_padded)\n",
        "y_pred = y_pred_probs.argmax(axis=1)\n",
        "\n",
        "# Decode predictions\n",
        "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "# Print statistics\n",
        "print_statistics(y_test, y_pred_decoded)\n"
      ]
    }
  ]
}